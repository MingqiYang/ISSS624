---
title: "Take-home Exercise 1: Geospatial Analytics for Social Good"
editor: visual
date: "`r Sys.Date()`"
execute: 
  warning: false
  message: false
---

## 1 Overview

Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world's accessible freshwater.

Developing countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.

To address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.

Geospatial analytics hold tremendous potential to address complex problems facing society. In this study, we apply appropriate global and local measures of spatial Association techniques to reveals the spatial patterns of Not Functional water points. For the purpose of this study, Nigeria will be used as the study country.

## 2 Getting Started

In the code chunk below, p_load() of pacman package is used to install and load the following R packages into R environment:

-   sf,

-   tidyverse,

-   tmap,

-   spdep, and

-   funModeling will be used for rapid Exploratory Data Analysis

```{r}
pacman::p_load(sf, tidyverse, tmap, spdep, funModeling)
```

## 3 Data Preparation

### 3.1 Importing Geospatial Data

In this in-class data, two geospatial data sets will be used, they are:

-   geo_export

-   nga_admbnda_adm2_osgof_20190417

#### 3.1.1 Importing water point geospatial data

First, we are going to import the water point geospatial data (i.e. geo_export) by using the code chunk below.

Note that in this exercise we use **EPSG** **26391**.

```{r eval=FALSE}
wp <- st_read(dsn = "geodata",
              layer = "geo_export") %>%
  filter(clean_coun == "Nigeria")
wp <- wp %>%
  st_transform(crs = 26391)
```

Next, write_rds() of readr package is used to save the extracted sf data table (i.e. wp) into an output file in rds data format. The output file is called wp_nga.rds and it is saved in geodata sub-folder.

```{r eval=FALSE}
write_rds(wp, "geodata/wp_nga.rds")
```

#### 3.1.2 Importing Nigeria LGA boundary data

Now, we are going to import the LGA boundary data into R environment by using the code chunk below.

Note that in this exercise we use **EPSG** **26391**.

```{r eval=FALSE}
nga <- st_read(dsn = "geodata",
               layer = "nga_admbnda_adm2_osgof_20190417") %>%
  st_transform(crs = 26391)
```

### 3.2 Data Wrangling

#### 3.2.1 Recoding NA values into string

In the code chunk below, replace_na() is used to recode all the NA values in status_cle field into Unknown.

```{r eval=FALSE}
wp_nga <- read_rds("geodata/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

In the code chunk below, freq() of funModeling package is used to display the distribution of status_cle field in *current* wp_nga.

```{r eval=FALSE}
freq(data=wp_nga, 
     input = 'status_cle')
```

#### 3.2.2 Extracting Water Point Data

In this section, we will extract the water point records by using classes in status_cle field.

##### 3.2.2.1 Extracting functional water point

In the code chunk below, filter() of dplyr is used to select functional water points.

```{r eval=FALSE}
wpt_functional <- wp_nga %>%
  filter(status_cle %in%
           c("Functional", 
             "Functional but not in use",
             "Functional but needs repair"))
```

```{r eval=FALSE}
freq(data=wpt_functional, 
     input = 'status_cle')
```

##### 3.2.2.2 Extracting non-functional water point

In the code chunk below, filter() of dplyr is used to select non-functional water points.

```{r eval=FALSE}
wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

```{r eval=FALSE}
freq(data=wpt_nonfunctional, 
     input = 'status_cle')
```

##### 3.2.2.3 Extracting unknown water point

```{r eval=FALSE}
wpt_unknown <- wp_nga %>%
  filter(status_cle == "Unknown")
```

#### 3.2.3 Performing Point-in-Polygon Count

Transforming the projection of wp_nga, wpt_functional and wpt_nonfunctional from EPSG:4326 to EPSG:26391.

```{r eval=FALSE}
wp_nga <- wp_nga %>%
  st_transform(crs = 26391)
```

```{r eval=FALSE}
wpt_functional <- wpt_functional %>%
  st_transform(crs = 26391)
wpt_nonfunctional <- wpt_nonfunctional %>%
  st_transform(crs = 26391)
wpt_unknown <- wpt_unknown %>%
  st_transform(crs = 26391)
```

```{r eval=FALSE}
nga_wp <- nga %>% 
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_nga))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt unknown` = lengths(
    st_intersects(nga, wpt_unknown)))
```

```{r eval=FALSE}
glimpse(nga_wp)
```

```{r eval=FALSE}
hist(nga_wp$`wpt non-functional`)
```

#### 3.2.4 Saving the Analytic Data Table

```{r eval=FALSE}
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt functional`/`total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`)
```

Things to learn from the code chunk above:

-   mutate() of dplyr package is used to derive two fields namely pct_functional and pct_non-functional.

Now, you have the tidy sf data table subsequent analysis. We will save the sf data table into rds format.

```{r eval=FALSE}
write_rds(nga_wp, "geodata/nga_wp.rds")
```

Before you end this section, please remember to delete away all the raw data. Notice that the only data file left is nga_wp.rds and it's file size is aroung 2.1MB.

## 4 Mapping

### 4.1 Plotting a choropleth map

The easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.

The code chunk below will draw a cartographic standard choropleth map as shown below.

```{r}
nga_wp <- read_rds("geodata/nga_wp.rds")
wp_functional <- qtm(nga_wp, "wpt functional")
wp_nonfunctional <- qtm(nga_wp, "wpt non-functional")

tmap_arrange(wp_functional, wp_nonfunctional, asp=1, ncol=2)
```

### 4.2 Data classification methods of tmap

Most choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.

tmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.

Plotting choropleth maps with built-in classification methods:

```{r}
tm_shape(nga_wp)+
  tm_fill(c("wpt functional","wpt non-functional"),
          n = 5,
          style = "jenks") +
  tm_borders(alpha = 0.5) +
  tm_layout(legend.position = c("right", "bottom"))
```

```{r}
tm_shape(nga_wp)+
  tm_fill(c("wpt functional","wpt non-functional"),
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(legend.position = c("right", "bottom"))
```

Change the map color:

```{r}
tm_shape(nga_wp)+
  tm_fill("wpt functional", 
          style = "jenks", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(main.title = "Distribution of Functional Water Points by ADM2 \n(Jenks classification)",
            main.title.position = "center",
            main.title.size = 1,
            legend.height = 0.45, 
            legend.width = 0.35,
            legend.outside = FALSE,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)

```

```{r}
tm_shape(nga_wp)+
  tm_fill("wpt non-functional", 
          style = "jenks", 
          palette = "Blues", 
          legend.hist = TRUE, 
          legend.is.portrait = TRUE,
          legend.hist.z = 0.1) +
  tm_layout(main.title = "Distribution of Non Functional Water Points by ADM2 \n(Jenks classification)",
            main.title.position = "center",
            main.title.size = 1,
            legend.height = 0.45, 
            legend.width = 0.35,
            legend.outside = FALSE,
            legend.position = c("right", "bottom"),
            frame = FALSE) +
  tm_borders(alpha = 0.5)
```

## 5 Spatial Weights and Spatial Autocorrelation

### 5.1 Computing Contiguity Spatial Weights

In this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a "queen" argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don't specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.

#### 5.1.1 Computing (QUEEN) contiguity based neighbours

```{r}
wm_q <- poly2nb(nga_wp, queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 774 area units in Nigeria. The most connected area unit has 14 neighbours. There is one area unit with no neighbour.

#### 5.1.2 Creating (ROOK) contiguity based neighbours

```{r}
wm_r <- poly2nb(nga_wp, queen=FALSE)
summary(wm_r)
```

The summary report above shows that there are 774 area units in Nigeria. The most connected area unit has 14 neighbours. There is one area unit with no neighbour.

#### 5.1.3 Plotting both Queen and Rook contiguity based neighbours maps

```{r}
longitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])
latitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])
coords <- cbind(longitude, latitude)
```

```{r}
par(mfrow=c(1,2))
plot(nga_wp$geometry, border="lightgrey")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red", main="Queen Contiguity")
plot(nga_wp$geometry, border="lightgrey")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red", main="Rook Contiguity")
```

#### 5.1.4 Row-standardised weights matrix

Next, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style="W"). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors' values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we'll stick with the style="W" option for simplicity's sake but note that other more robust options are available, notably style="B".

```{r}
set.ZeroPolicyOption(TRUE)
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE,)
rswm_q
```

### 5.2 Computing distance based neighbours

In this section, you will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.

The function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument.

#### 5.2.1 Deriving the centroid

```{r}
longitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])
latitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])
coords <- cbind(longitude, latitude)
```

or:

```{r}
coords1 <- st_centroid(st_geometry(nga_wp))
```

#### 5.2.2 Determine the cut-off distance

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is 72.139 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

#### 5.2.3 Computing fixed distance weight matrix

Now, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.

```{r}
wm_d73 <- dnearneigh(coords1, 0, 72140)
wm_d73
```

#### 5.2.4 Plotting fixed distance weight matrix

Next, we will plot the distance weight matrix by using the code chunk below.

```{r}
par(mfrow=c(1,2))
plot(nga_wp$geometry, border="lightgrey")
plot(k1, coords, add=TRUE, col="red", length=0.08, main="1st nearest neighbours")
plot(nga_wp$geometry, border="lightgrey")
plot(wm_d73, coords, add=TRUE, pch = 19, cex = 0.6, main="Distance link")
```

#### 5.2.5 Computing adaptive distance weight matrix

One of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.

It is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.

```{r}
knn8 <- knn2nb(knearneigh(coords, k=8))
knn8
```

#### 5.2.6 Plotting distance based neighbours

We can plot the weight matrix using the code chunk below.

```{r}
plot(nga_wp$geometry, border="lightgrey")
plot(knn8, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

5.2.7 Computing weights based on IDW (Inverse Distance Weights)

```{r}
dist <- nbdists(wm_d73, coords)
ids <- lapply(dist, function(x) 1/(x))
```

```{r}
rswm_ids <- nb2listw(wm_d73, glist=ids, style="B", zero.policy=TRUE)
rswm_ids
```

### 5.3 Global Spatial Autocorrelation: Moran's I

```{r}
moran.test(nga_wp$`pct_non-functional`, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

#### 5.3.1 Computing Monte Carlo Moran's I

The code chunk below performs permutation test for Moran's I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.

```{r}
set.seed(1234)
mc= moran.mc(nga_wp$`pct_non-functional`, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
mc
```

#### 5.3.2 Visualising Monte Carlo Moran's I

It is always a good practice for us the examine the simulated Moran's I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.

```{r}
hist(mc$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```

## 6 Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

### 6.1 Computing local Moran's I

#### 6.1.1 Compute Moran's I

To compute local Moran's I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

```{r}
fips <- order(nga_wp$ADM2_EN)
localMI <- localmoran(nga_wp$`wpt non-functional`, rswm_q)
head(localMI)
```

#### 6.1.2 Mapping the local Moran's I

Before mapping the local Moran's I map, it is wise to append the local Moran's I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame.

```{r}
nga_wp.localMI <- cbind(nga_wp,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

#### 6.1.3 Mapping local Moran's I values

Using choropleth mapping functions of tmap package, we can plot the local Moran's I values by using the code chinks below.

```{r}
tm_shape(nga_wp.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

#### 6.1.4 Mapping local Moran's I p-values

The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

The code chunks below produce a choropleth map of Moran's I p-values by using functions of tmap package.

```{r}
tm_shape(nga_wp.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)
```

#### 6.1.5 Mapping both local Moran's I values and p-values

For effective interpretation, it is better to plot both the local Moran's I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{r}
localMI.map <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

### 6.2 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

#### 6.2.1 Plotting Moran scatterplot

The Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.

```{r}
nci <- moran.plot(nga_wp$`wpt non-functional`, rswm_q,
                  labels=as.character(nga_wp$ADM2_EN), 
                  xlab="Non Functional Water Points", 
                  ylab="Spatially Lag Non Functional Water Points")
```

#### 6.2.2 Plotting Moran scatterplot with standardised variable

First we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

```{r}
nga_wp$Z.nonfun <- scale(nga_wp$`wpt non-functional`) %>% 
  as.vector 
```

The as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.

Now, we are ready to plot the Moran scatterplot again by using the code chunk below.

```{r}
nci2 <- moran.plot(nga_wp$Z.nonfun, rswm_q,
                   labels=as.character(nga_wp$ADM2_EN),
                   xlab="z-Non Functional Water Points", 
                   ylab="Spatially Lag z-Non Functional Water Points")
```

6.2.3 Preparing LISA map classes

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
nga_wp$lag_nonfun <- lag.listw(rswm_q, nga_wp$`wpt non-functional`)
DV <- nga_wp$lag_nonfun - mean(nga_wp$lag_nonfun)     
LM_I <- localMI[,1]   
signif <- 0.05       
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4    
quadrant[localMI[,5]>signif] <- 0
```

#### 6.2.4 Plotting LISA map

For effective interpretation, it is better to plot both the local Moran's I values map and its corresponding p-values map next to each other.

The code chunk below will be used to create such visualisation.

```{r}
nonfun <- qtm(nga_wp, "wpt non-functional")

nga_wp.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAmap <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)

tmap_arrange(nonfun, LISAmap, 
             asp=1, ncol=2)
```

## 7 Hot Spot and Cold Spot Area Analysis

Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.

The analysis consists of three steps:

-   Deriving spatial weight matrix (which can be found in ***5.2 Computing distance based neighbours***)

-   Computing Gi statistics

-   Mapping Gi statistics

### 7.1 Deriving spatial weight matrix

Refer to 5.2 for deriving the centroid, determining the cut-off distance, and computing fixed distance weight matrix.

nb2listw() is used to convert the nb object into spatial weights object

```{r}
wm73_lw <- nb2listw(wm_d73, style = 'B')
summary(wm73_lw)
```

Computing adaptive distance weight matrix:

```{r}
knn <- knn2nb(knearneigh(coords, k=8))
knn
```

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

### 7.2 Computing Gi statistics

#### 7.2.1 Gi statistics using fixed distance

```{r}
fips <- order(nga_wp$ADM2_EN)
gi.fixed <- localG(nga_wp$`wpt non-functional`, wm73_lw)
```

```{r}
nga_wp.gi <- cbind(nga_wp, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

7.2.2 Mapping Gi values with fixed distance weights

```{r}
nonfun <- qtm(nga_wp, "wpt non-functional")

Gimap <-tm_shape(nga_wp.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(nonfun, Gimap, asp=1, ncol=2)
```

#### 7.2.3 Gi statistics using adaptive distance

```{r}
fips <- order(nga_wp$ADM2_EN)
gi.adaptive <- localG(nga_wp$`wpt non-functional`, knn_lw)
nga_wp.gi <- cbind(nga_wp, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

#### 7.2.4 Mapping Gi values with adaptive distance weights

It is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r}
nonfun<- qtm(nga_wp, "wpt non-functional")

Gimap <- tm_shape(nga_wp.gi) + 
  tm_fill(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(nonfun, 
             Gimap, 
             asp=1, 
             ncol=2)
```

## 8 Conclusion

This project allows us to analyze water points in Nigeria using spatial analysis methods to discover spatial patterns. Throughout the project, we have a clear understanding of geospatial data wrangling, geospatial analysis, visualisation, and geospatial autocorrelation.
